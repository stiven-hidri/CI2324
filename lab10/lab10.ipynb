{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright **`(c)`** 2023 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB10\n",
    "\n",
    "Use reinforcement learning to devise a tic-tac-toe player.\n",
    "\n",
    "### Deadlines:\n",
    "\n",
    "* Submission: [Dies Natalis Solis Invicti](https://en.wikipedia.org/wiki/Sol_Invictus)\n",
    "* Reviews: [Befana](https://en.wikipedia.org/wiki/Befana)\n",
    "\n",
    "Notes:\n",
    "\n",
    "* Reviews will be assigned  on Monday, December 4\n",
    "* You need to commit in order to be selected as a reviewer (ie. better to commit an empty work than not to commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import random\n",
    "from numpy import linspace\n",
    "\n",
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.board = [[0 for _ in range(3)] for _ in range(3)]\n",
    "        self.current_player = 1\n",
    "\n",
    "    def print_board(self):\n",
    "        elements = ['X', 'O']\n",
    "        for row in self.board:\n",
    "            for e in row:\n",
    "                print(f\"{elements[e-1]} \", end=\"\")\n",
    "            print()\n",
    "\n",
    "    def make_move(self, row, col):\n",
    "        if self.is_valid_move(row, col):\n",
    "            self.board[row][col] = self.current_player\n",
    "            self.switch_player()\n",
    "        else:\n",
    "            print(\"Invalid move.\")\n",
    "\n",
    "    def is_valid_move(self, row, col):\n",
    "        return 0 <= row < 3 and 0 <= col < 3 and self.board[row][col] == 0\n",
    "\n",
    "    def switch_player(self):\n",
    "        self.current_player = 2 if self.current_player == 1 else 1\n",
    "\n",
    "    def make_random_move(self):\n",
    "        empty_cells = [(i, j) for i in range(3) for j in range(3) if self.board[i][j] == 0]\n",
    "        if empty_cells:\n",
    "            row, col = random.choice(empty_cells)\n",
    "            self.make_move(row, col)\n",
    "\n",
    "    def check_winner(self):\n",
    "        # Check rows, columns, and diagonals for a winner\n",
    "        for i in range(3):\n",
    "            if self.board[i][0] == self.board[i][1] == self.board[i][2] != 0 or \\\n",
    "               self.board[0][i] == self.board[1][i] == self.board[2][i] != 0:\n",
    "                return self.board[i][0]\n",
    "\n",
    "        if self.board[0][0] == self.board[1][1] == self.board[2][2] != 0 or \\\n",
    "           self.board[0][2] == self.board[1][1] == self.board[2][0] != 0:\n",
    "            return self.board[1][1]\n",
    "\n",
    "        return None\n",
    "\n",
    "    def is_board_full(self):\n",
    "        return all(self.board[i][j] != 0 for i in range(3) for j in range(3))\n",
    "\n",
    "    def play_with_agents(self, agents):\n",
    "        agent = agents[self.current_player-1]\n",
    "        while True:\n",
    "            if self.current_player == 1:\n",
    "                action = agent.choose_action(self.board)\n",
    "                self.make_move(action[0], action[1])   \n",
    "            else:\n",
    "                self.make_random_move()\n",
    "\n",
    "            winner = self.check_winner()\n",
    "            if winner:\n",
    "                if winner == 1:\n",
    "                    return 1\n",
    "                else:\n",
    "                    return 0\n",
    "\n",
    "            if self.is_board_full():\n",
    "                return 0\n",
    "\n",
    "\n",
    "    def play_with_agent(self, agent, start):\n",
    "        self.current_player = start\n",
    "        while True:\n",
    "            if self.current_player == 1:\n",
    "                action = agent.choose_action(self.board)\n",
    "                self.make_move(action[0], action[1])   \n",
    "            else:\n",
    "                self.make_random_move()\n",
    "\n",
    "            winner = self.check_winner()\n",
    "            if winner:\n",
    "                if winner == 1:\n",
    "                    return 1\n",
    "                else:\n",
    "                    return 0\n",
    "\n",
    "            if self.is_board_full():\n",
    "                return 0\n",
    "\n",
    "class TicTacToeRND:\n",
    "    def get_valid_actions(self, state):\n",
    "        # Return a list of valid actions for the given state\n",
    "        a =  [(i, j) for i in range(3) for j in range(3) if state[i][j] == 0]\n",
    "        return a\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        return random.choice(self.get_valid_actions(state))\n",
    "\n",
    "class TicTacToeRL:\n",
    "    def __init__(self, learning_rate=0.5, discount_factor=0.7, exploration_prob=0.1):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.exploration_prob = exploration_prob\n",
    "\n",
    "        # Q-table to store Q-values for state-action pairs\n",
    "        self.q_table = {}\n",
    "\n",
    "    def get_state_key(self, state):\n",
    "        return str(state)\n",
    "\n",
    "    def get_valid_actions(self, state):\n",
    "        # Return a list of valid actions for the given state\n",
    "        a =  [(i, j) for i in range(3) for j in range(3) if state[i][j] == 0]\n",
    "        return a\n",
    "\n",
    "    def get_q_value(self, state, action):\n",
    "        state_key = self.get_state_key(state)\n",
    "        return self.q_table.get((state_key, action), 0.0)\n",
    "\n",
    "    def update_q_value(self, state, action, new_value):\n",
    "        state_key = self.get_state_key(state)\n",
    "        self.q_table[(state_key, action)] = new_value\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        # Epsilon-greedy strategy for action selection\n",
    "        if random.uniform(0, 1) <= self.exploration_prob:\n",
    "            return random.choice(self.get_valid_actions(state))\n",
    "        else:\n",
    "            # Choose the action with the highest Q-value\n",
    "            q_values = [self.get_q_value(state, action) for action in self.get_valid_actions(state)]\n",
    "            max_q_value = max(q_values, default=0.0)\n",
    "            best_actions = [action for action, q_value in zip(self.get_valid_actions(state), q_values) if q_value == max_q_value]\n",
    "            return random.choice(best_actions)\n",
    "\n",
    "    def train(self, state, action, reward, next_state):\n",
    "        current_q_value = self.get_q_value(state, action)\n",
    "        max_q_value_next = max([self.get_q_value(next_state, next_action) for next_action in self.get_valid_actions(next_state)], default=0.0)\n",
    "\n",
    "        new_q_value = current_q_value + self.learning_rate * (reward + self.discount_factor * max_q_value_next - current_q_value)\n",
    "        self.update_q_value(state, action, new_q_value)\n",
    "\n",
    "def tic_tac_toe_rl_train():\n",
    "    # Initialize the RL model\n",
    "    agents = (TicTacToeRL(0.5, 0.7, 0.1), TicTacToeRL(0.5, 0.7, 0.1))\n",
    "    # Training loop\n",
    "    num_episodes = 100000\n",
    "    for ep in range(num_episodes):\n",
    "        if ep < num_episodes-1:\n",
    "            print(f\"TRAINING: {ep+1}/{num_episodes}\", end=\"\\r\")\n",
    "        else:\n",
    "            print(f\"TRAINING COMPLETED\\n\")\n",
    "        \n",
    "        history = ([],[])\n",
    "        start = random.choice([0,1])\n",
    "        turn = start\n",
    "        cntTurn = 0\n",
    "        game = TicTacToe()\n",
    "        state = [[0,0,0],[0,0,0],[0,0,0]]\n",
    "        while True:\n",
    "            # Player 1 (RL agent) move\n",
    "            action = agents[turn].choose_action(state)\n",
    "            game.make_move(action[0], action[1])\n",
    "            history[turn].append((state, action, game.board))\n",
    "\n",
    "            cntTurn+=1\n",
    "\n",
    "            if cntTurn>=5:\n",
    "\n",
    "                # Check for a winner or a tie\n",
    "                winner = game.check_winner()\n",
    "\n",
    "                if winner:\n",
    "                    loser = 1 if winner == 2 else 2\n",
    "                    n=len(history[winner-1])\n",
    "\n",
    "                    for i, h in enumerate(history[winner-1]):\n",
    "                        scores = linspace(0.1,1,num=n)**2\n",
    "                        agents[winner-1].train(h[0], h[1], scores[i], h[2])\n",
    "\n",
    "                    n=len(history[loser-1])\n",
    "                    for i,h in enumerate(history[loser-1]):\n",
    "                        scores = linspace(-.1,-.1,num=n)**2\n",
    "                        agents[loser-1].train(h[0], h[1], scores[i], h[2])\n",
    "\n",
    "                    break\n",
    "\n",
    "                if game.is_board_full():\n",
    "                    n=len(history[start])\n",
    "                    for i, h in enumerate(history[start]):\n",
    "                        scores = linspace(-.1,-.5,num=n)**2\n",
    "                        agents[start].train(h[0], h[1], scores[i], h[2])\n",
    "\n",
    "                    n=len(history[1-start])\n",
    "                    for i, h in enumerate(history[1-start]):\n",
    "                        scores = linspace(-.01,-3.,num=n)**2\n",
    "                        agents[1-start].train(h[0], h[1], scores[i], h[2])\n",
    "\n",
    "                    break\n",
    "\n",
    "            state = deepcopy(game.board)\n",
    "\n",
    "            turn = 1 - turn\n",
    "\n",
    "    return agents[0]\n",
    "\n",
    "def tic_tac_toe_rl_train_random(x):\n",
    "    # Initialize the RL model\n",
    "    agents = (TicTacToeRL(*x), TicTacToeRND())\n",
    "\n",
    "    # Training loop\n",
    "    num_episodes = 300000\n",
    "    for ep in range(num_episodes):\n",
    "        if ep <num_episodes-1:\n",
    "            print(f\"TRAINING: {round((ep+1)/num_episodes*100, 2)}%\", end=\"\\r\")\n",
    "        else:\n",
    "            print(f\"TRAINING COMPLETED!\\n\")\n",
    "\n",
    "        game = TicTacToe()\n",
    "        state = [[0,0,0],[0,0,0],[0,0,0]]\n",
    "        history = ([],[])\n",
    "        start = random.choice([0,1])\n",
    "        turn = start\n",
    "        cntTurn = 0\n",
    "        while True:\n",
    "            # Player 1 (RL agent) move\n",
    "            action = agents[turn].choose_action(state)\n",
    "            game.make_move(action[0], action[1])\n",
    "            history[turn].append((state, action, game.board))\n",
    "\n",
    "            cntTurn+=1\n",
    "\n",
    "            if cntTurn>=5:\n",
    "\n",
    "                # Check for a winner or a tie\n",
    "                winner = game.check_winner()\n",
    "\n",
    "                if winner == 1:\n",
    "                    n=len(history[0])\n",
    "                    for i, h in enumerate(history[0]):\n",
    "                        scores = linspace(.1,1,num=n)**2\n",
    "                        agents[0].train(h[0], h[1], scores[i], h[2])\n",
    "\n",
    "                    break\n",
    "\n",
    "                if winner == 2:\n",
    "                    n=len(history[0])\n",
    "                    for i, h in enumerate(history[0]):\n",
    "                        scores = linspace(-.01,-.1,num=n)**2\n",
    "                        agents[0].train(h[0], h[1], scores[i], h[2])\n",
    "\n",
    "                    break\n",
    "\n",
    "                if game.is_board_full():\n",
    "                    n=5\n",
    "                    scoreMAX = 0.1 if start == 0 else 0.3\n",
    "                    scores = linspace(.01,scoreMAX,num=n)**2\n",
    "                    for i, h in enumerate(history[0]):\n",
    "                        agents[0].train(h[0], h[1], scores[i], h[2])\n",
    "\n",
    "                    break\n",
    "\n",
    "            state = deepcopy(game.board)\n",
    "\n",
    "            turn = 1 - turn\n",
    "\n",
    "    return agents[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent = tic_tac_toe_rl_train_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(agent):\n",
    "    num_episodes=10000\n",
    "    winsF = 0\n",
    "    winsS = 0\n",
    "\n",
    "    for _ in range(num_episodes):\n",
    "        game = TicTacToe()\n",
    "        winsF += game.play_with_agent(agent, 1)\n",
    "        winsS += game.play_with_agent(agent, 2)\n",
    "\n",
    "\n",
    "    print(f\"wins F:{round(winsF/num_episodes*100, 2)}%\")\n",
    "    print(f\"wins S:{round(winsS/num_episodes*100, 2)}%\")\n",
    "\n",
    "    # return winsF+winsS\n",
    "\n",
    "import numpy\n",
    "\n",
    "def validate():\n",
    "    a = linspace(0, 1,num=11)[1:]\n",
    "    b = deepcopy(a)\n",
    "    c = deepcopy(a)\n",
    "    i=1\n",
    "\n",
    "    mesh = numpy.array(numpy.meshgrid(a, b, c)).T.reshape(-1, 3)\n",
    "    finals = []\n",
    "\n",
    "    for x in mesh:\n",
    "        a = tic_tac_toe_rl_train_random(x)\n",
    "        score = test(a)\n",
    "        finals.append((x, a, score))\n",
    "        i+=1\n",
    "        print(f\"{numpy.round(i/mesh.shape[0]*100,2)}%\", end=\"\\r\")\n",
    "\n",
    "    finals.sort(key=lambda f:f[2], reverse=True)\n",
    "\n",
    "    for f in finals:\n",
    "        print(f\"{str(f[0])} -> {f[2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent2=tic_tac_toe_rl_train_random([.2,1,.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins F:94.51%\n",
      "wins S:94.0%\n"
     ]
    }
   ],
   "source": [
    "test(agent2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci-fLJ3OwGs-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
